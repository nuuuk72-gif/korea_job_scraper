from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import csv

# -----------------------------------------------
# 1. Chrome ã‚’èµ·å‹•ï¼ˆãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹å¯ï¼‰
# -----------------------------------------------
options = webdriver.ChromeOptions() #options : ChromeOptions ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
options.add_argument("--headless")  # ãƒ–ãƒ©ã‚¦ã‚¶éè¡¨ç¤º "--headless":Chrome ã«æ¸¡ã™å®Ÿéš›ã®å¼•æ•°ï¼ˆãƒ•ãƒ©ã‚°ï¼‰
options.add_argument("--no-sandbox") #.add_argument(): ãã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¼•æ•°ã‚’è¶³ã™ãƒ¡ã‚½ãƒƒãƒ‰
options.add_argument("--disable-dev-shm-usage")

driver = webdriver.Chrome(options=options)


# -----------------------------------------------
# 2. ãƒ­ãƒ¼ã‚«ãƒ« HTML ã«ã‚¢ã‚¯ã‚»ã‚¹
# -----------------------------------------------
url = "http://localhost:8080/mock_jobs.html"
driver.get(url)

# -----------------------------------------------
# 3. æ±‚äººã‚«ãƒ¼ãƒ‰å–å¾—ï¼ˆCSSã‚»ãƒ¬ã‚¯ã‚¿ã¯HTMLã«åˆã‚ã›ã‚‹ï¼‰
# -----------------------------------------------
try:
    job_cards = WebDriverWait(driver, 10).until(
        EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".job-card")) 
        #æŒ‡å®šã—ãŸã‚»ãƒ¬ã‚¯ã‚¿ã«ä¸€è‡´ã™ã‚‹è¦ç´ ãŒ ãƒšãƒ¼ã‚¸ã®ã©ã“ã‹ã«å­˜åœ¨ã™ã‚‹çŠ¶æ…‹ã«ãªã‚‹ã¾ã§å¾…ã¤
    ) #.job-card ã®è¦ç´ ãŒå‡ºã¦ãã‚‹ã¾ã§ã€æœ€å¤§10ç§’å¾…ã¤
except:
    job_cards = []

print(f"æ±‚äººã‚«ãƒ¼ãƒ‰æ•°: {len(job_cards)}")  # â†ã“ã“ã§ä»¶æ•°ç¢ºèª

# -----------------------------------------------
# 4. æ±‚äººæƒ…å ±å–å¾—
# -----------------------------------------------
results = []
for job in job_cards:
    try:
        title = job.find_element(By.CSS_SELECTOR, ".job-title").text
    except:
        title = ""
    try:
        company = job.find_element(By.CSS_SELECTOR, ".company-name").text
    except:
        company = ""
    try:
        location = job.find_element(By.CSS_SELECTOR, ".location").text
    except:
        location = ""
    try:
        salary = job.find_element(By.CSS_SELECTOR, ".salary").text
    except:
        salary = ""
    try:
        description = job.find_element(By.CSS_SELECTOR, ".company-description").text
    except:
        description = ""
    try:
        tags = [tag.text for tag in job.find_elements(By.CSS_SELECTOR, ".tags .tag")]
    except:
        tags = []
    try:
        link = job.find_element(By.CSS_SELECTOR, "a").get_attribute("href")
    except:
        link = ""
    
    results.append([title, company, location, salary, description, tags, link])

# -----------------------------------------------
# 5. CSV ã«ä¿å­˜
# -----------------------------------------------
with open("C:/Users/user/my_project/python/korea_job_scraper/jobs.csv", "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["ã‚¿ã‚¤ãƒˆãƒ«", "ä¼æ¥­å", "å‹¤å‹™åœ°", "çµ¦ä¸","èª¬æ˜", "ã‚¿ã‚°", "URL"])
    writer.writerows(results)

print("ğŸ‰ Selenium ã§ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Œäº†ï¼ jobs.csv ã‚’ç¢ºèªã—ã¦ã­ï¼")

# -----------------------------------------------
# 6. ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã‚‹
# -----------------------------------------------
driver.quit()
